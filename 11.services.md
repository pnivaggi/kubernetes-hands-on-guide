# Services

Services provide discoverable names and load balancing to Pod replicas. The services and Pods remain agnostic from IPs with the help of the Kubernetes DNS control plane component. Similar to a Deployment, the Service determines the Pods it works on with the help of label selection.

Every Service needs to define a type. The type determines how the Service exposes the matching Pods, as listed below:

|Type        |Description                                                                                            |
|------------|-------------------------------------------------------------------------------------------------------|
|ClusterIP   |Exposes the Service on a cluster-internal IP. Only reachable from within the cluster.                  |
|NodePort    |Exposes the Service on each node’s IP address at a static port. Accessible from outside of the cluster.|
|LoadBalancer|Exposes the Service externally using a cloud provider’s load balancer.                                 |
|ExternalName|Maps a Service to a DNS name.                                                                          |
|            |                                                                                                       |

## ClusterIP Service

ClusterIP is the default type of Service. It exposes the Service on a cluster-internal IP address.

### Task 1. Expose Pod with ClusterIP Service

As usual service can be created with declarative or imperative patterns, let use the `--expose` flag to create a ClusterIP service to expose a nginx Pod:

```bash
kubectl run nginx --image=nginx --restart=Never --port=80 --expose
```

You should have a similar output:

```console
eti-lab> kubectl run nginx --image=nginx --restart=Never --port=80 --expose
service/nginx created
pod/nginx created
```

### Task 2. Check ClusterIP Service

Let's check the IP address and port assigned to nginx service just created:

```bash
kubectl describe svc nginx
```

```console
eti-lab> kubectl describe svc nginx
Name:              nginx
Namespace:         default
Labels:            <none>
Annotations:       <none>
Selector:          run=nginx
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.96.76.154
IPs:               10.96.76.154
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         10.244.2.107:80
Session Affinity:  None
Events:            <none>
```

In our lab we can notice:

- the Selector for serving Pods is `run=nginx` which should match with the nginx Pod labels
- the IP address allocated for the ClusterIP nginx service is `10.96.76.154`
- the Enpoints list is `10.244.2.107:80` which should correspond to the nginx Pod ip address

### Task 3. Understand ClusterIP Service Selector and Endpoints

Let's check the nginx Pod labels matches the Selector and IP address matches the service Endpoints:

```bash
kubectl describe pods nginx
```

You should have a similar output:

```console
eti-lab> kubectl describe pods nginx
Name:             nginx
Namespace:        default
Priority:         0
Service Account:  default
Node:             demo1-worker2/172.18.0.3
Start Time:       Tue, 01 Nov 2022 08:39:20 +0000
Labels:           run=nginx         ## Label matches the service Selector
Annotations:      <none>
Status:           Running
IP:               10.244.2.107      ## IP address matches the service Endpoints
IPs:
  IP:  10.244.2.107
```

### Task 4. Check ClusterIP Service reachability

Let's check the nginx service is reachable from another Pod:

```bash
kubectl run busybox --image=busybox --restart=Never -it -- wget -O- http://nginx
kubectl delete pod busybox
```

```console
eti-lab> kubectl run busybox --image=busybox --restart=Never -it -- wget -O- http://nginx
kubectl delete pod busybox
Connecting to nginx (10.96.76.154:80)
writing to stdout
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
-                    100% |********************************|   615  0:00:00 ETA
written to stdout
pod "busybox" deleted
```

You notice we can address the service directly with its name in the URL. It works because our testing Pod was in the same `default` namespace and `nginx` is resolvable in that namespace.

### Task 5. Check ClusterIP Service reachability from another namespace

Let's test from another namespace called `notdefault`:

```bash
kubectl create ns notdefault
kubectl -n notdefault run busybox --image=busybox --restart=Never -it -- wget -O- http://nginx
kubectl -n notdefault delete pod busybox
```

You should have a similar output:

```console
eti-lab> kubectl create ns notdefault
kubectl -n notdefault run busybox --image=busybox --restart=Never -it -- wget -O- http://nginx
kubectl -n notdefault delete pod busybox
namespace/notdefault created
wget: bad address 'nginx'
pod notdefault/busybox terminated (Error)
pod "busybox" deleted
```

Notice that we get `wget: bad address 'nginx'`. In fact the DNS resolution is still working between namespace but the service FQDN is required from others namespaces with the pattern `<service-name>.<namespace-name>.svc.cluster.local`. Let's try it:

```bash
kubectl -n notdefault run busybox --image=busybox --restart=Never -it -- wget -O- http://nginx.default.svc.cluster.local
kubectl -n notdefault delete pod busybox
```

You should have a similar output:

```console
eti-lab> kubectl -n notdefault run busybox --image=busybox --restart=Never -it -- wget -O- http://nginx.default.svc.cluster.local
kubectl -n notdefault delete pod busybox
Connecting to nginx.default.svc.cluster.local (10.96.76.154:80)
writing to stdout
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
-                    100% |********************************|   615  0:00:00 ETA
written to stdout
pod "busybox" deleted
```

Delete `notdefault` namespace:

```bash
kubectl delete ns notdefault 
```

You should have a similar output

```console
eti-lab> kubectl delete ns notdefault 
namespace "notdefault" deleted
```

## Kubectl proxy for Troubleshooting

For now the ClusterIP service is only reachable from inside the cluster. Proxy service on K8s API allow to give access from a remote host for troubleshooting purposes.

### Task 6. Create Proxy

Run the following command:

```bash
kubectl proxy --port=9999 &
```

You should have a similar output:

```console
eti-lab> kubectl proxy --port=9999 &
[1] 923122
eti-lab> Starting to serve on 127.0.0.1:9999
```

### Task 7. Check access to service via Proxy
 
Then check you can get access to the nginx service by running the following:

```bash
curl -L localhost:9999/api/v1/namespaces/default/services/nginx/proxy
```

You should have a similar output:

```console
eti-lab> curl -L localhost:9999/api/v1/namespaces/default/services/nginx/proxy
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

### Task 8. Delete Proxy

Let's kill the `kubectl proxy` process"

```bash
kill -9 "$(ps -ef | awk '/[k]ubectl/{print $2}')"
```

```console
eti-lab> kill -9 "$(ps -ef | awk '/[k]ubectl/{print $2}')"
eti-lab> 
[1]+  Killed                  kubectl proxy --port=9999
```

Check there is no access to the nginx service anymore:

```bash
curl -L localhost:9999/api/v1/namespaces/default/services/nginx/proxy
```

```console
eti-lab> curl -L localhost:9999/api/v1/namespaces/default/services/nginx/proxy
curl: (7) Failed to connect to localhost port 9999 after 0 ms: Connection refused 
```

## NodePort Service

Declaring a Service with type NodePort exposes access through the node’s IP address and can be resolved from outside of the Kubernetes cluster. The node’s IP address can be reached in combination with a port number in the range of 30000 and 32767, assigned automatically upon the creation of the Service.

### Task 9. Create NodePort Service

Let patch the nginx service to change the type to `NodePort`:

```bash
kubectl patch service nginx -p '{ "spec": {"type": "NodePort"} }'
```

```console
eti-lab> kubectl patch service nginx -p '{ "spec": {"type": "NodePort"} }'
service/nginx patched
```

### Task 10. Check NodePort Service

```bash
kubectl describe service nginx 
```

You should have a similar output:

```console
eti-lab> kubectl describe service nginx
Name:                     nginx
Namespace:                default
Labels:                   <none>
Annotations:              <none>
Selector:                 run=nginx
Type:                     NodePort # service type = Nodeport
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.96.11.151
IPs:                      10.96.11.151
Port:                     <unset>  80/TCP
TargetPort:               80/TCP
NodePort:                 <unset>  31280/TCP # automatic port assignment
Endpoints:                192.168.121.77:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
```

You can notice the `nodePort` has been assigned automatically, it is possible to assign it by configuration. Let's patch the nginx service again to configure `nodePort = 30080`.

### Task 11. Assign nodePort value

Run the following command to create the patch configuration file:

```bash
cat > patch-nginx-service.yaml << EOF
spec:
  ports:
  - nodePort: 30080
    port: 80
    protocol: TCP
    targetPort: 80
EOF
```

Then you can apply the patch by running:

```bash
kubectl patch service nginx --patch-file=patch-nginx-service.yaml
```

```console
eti-lab> kubectl patch service nginx --patch-file=patch-nginx-service.yaml
service/nginx patched
```

Check the service configuration again:

```console
eti-lab> kubectl describe svc nginx
Name:                     nginx
Namespace:                default
Labels:                   <none>
Annotations:              <none>
Selector:                 run=nginx
Type:                     NodePort # service type = Nodeport
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.96.58.190
IPs:                      10.96.58.190
Port:                     <unset>  80/TCP
TargetPort:               80/TCP
NodePort:                 <unset>  30080/TCP # configured port
Endpoints:                192.168.121.74:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
```

### Task 12. Check NodePort service reachability

Let's check the nginx service is reachable from outside now using IP address of demo-worker node:

```bash
export demoworker_ip="$(kubectl get node demo-worker -o go-template --template '{{(index .status.addresses 0).address}}')"
echo $demoworker_ip
curl http://$demoworker_ip:30080
```

You should have a similar output:

```console
eti-lab> export demoworker_ip="$(kubectl get node demo-worker -o go-template --template '{{(index .status.addresses 0).address}}')"
eti-lab> echo $demoworker_ip
172.18.0.4
eti-lab> curl http://$demoworker_ip:30080
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

or using IP address of demo-worker2 node:

```bash
export demoworker2_ip="$(kubectl get node demo-worker2 -o go-template --template '{{(index .status.addresses 0).address}}')"
echo $demoworker2_ip
curl http://$demoworker2_ip:30080
```

You should have a similar output:

```console
eti-lab> export demoworker2_ip="$(kubectl get node demo-worker2 -o go-template --template '{{(index .status.addresses 0).address}}')"
eti-lab> echo $demoworker2_ip
172.18.0.2
eti-lab> curl http://$demoworker2_ip:30080
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

## LoadBalancer Service

On cloud providers which support external load balancers, setting the type field to LoadBalancer provisions a load balancer for your Service. The actual creation of the load balancer happens asynchronously, and information about the provisioned balancer is published in the Service's `.status.loadBalancer` field.

In our lab we will install metallb as external load balancers.

### Task 13. Install metallb

```bash
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.7/config/manifests/metallb-native.yaml
```

You should have a similar output:

```console
eti-lab> kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.7/config/manifests/metallb-native.yaml
namespace/metallb-system created
customresourcedefinition.apiextensions.k8s.io/addresspools.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created
customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created
customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created
customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created
customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created
serviceaccount/controller created
serviceaccount/speaker created
role.rbac.authorization.k8s.io/controller created
role.rbac.authorization.k8s.io/pod-lister created
clusterrole.rbac.authorization.k8s.io/metallb-system:controller created
clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created
rolebinding.rbac.authorization.k8s.io/controller created
rolebinding.rbac.authorization.k8s.io/pod-lister created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created
secret/webhook-server-cert created
service/webhook-service created
deployment.apps/controller created
daemonset.apps/speaker created
validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created
```

### Task 14. Get IP addresses range for metallb

We will setup MetalLb using layer2 protocol. We need to provide MetalLb a range of IP addresses it controls. We want this range to be on the docker kind network.

```bash
docker network inspect -f '{{.IPAM.Config}}' kind
```

You should have a similar output

```console
eti-lab> docker network inspect -f '{{.IPAM.Config}}' kind
[{172.18.0.0/16  172.18.0.1 map[]} {fc00:f853:ccd:e793::/64   map[]}]
```

We notice the CIDR used by Docker is 172.18.0.0/16 so we can allocate to MetalLb the following range 172.18.255.200-172.18.255.250.

### Task 15. Configure IP addresses range for metallb

Run the following command to define `ip-range.yaml` configuration file for the IP addresses range:

```bash
cat > ip-range.yaml << EOF
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: metallb-ippool
  namespace: metallb-system
spec:
  addresses:
  - 172.18.255.200-172.18.255.250
  autoAssign: true
  avoidBuggyIPs: false
EOF
```

Then run the following command to apply the configuration file:

```bash
kubectl apply -f ip-range.yaml
```

You should have a similar output:

```console
eti-lab> kubectl apply -f ip-range.yaml
ipaddresspool.metallb.io/metallb-ippool created
```

### Task 16. Configure metallb for l2 advertisement mode

Layer 2 mode does not require the IPs to be bound to the network interfaces of your worker nodes. It works by responding to ARP requests on your local network directly, to give the machine’s MAC address to clients.

Run the following command to define `l2advertisement.yaml` configuration file for the IP addresses range:

```bash
cat > l2advertisement.yaml << EOF
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: metallb-l2adv
  namespace: metallb-system
spec:
  ipAddressPools:
  - metallb-ippool
EOF
```

Then run the following command to apply the configuration file:

```bash
kubectl apply -f l2advertisement.yaml
```

You should have a similar output:

```console
eti-lab> kubectl apply -f l2advertisement.yaml
l2advertisement.metallb.io/metallb-l2adv created
```

### Task 17. Deploy nginx workload in test namespace

Run the following command to deploy a nginx workload in test namespace

```bash
kubectl delete ns test
kubectl create ns test
kubectl run nginx --image=nginx --restart=Never --port=80 -n test
```

### Task 18. Deploy a LoabBalancer type service

Use the following command to define the LoadBalancer service configuration file:

```bash
cat > nginx-lb.yaml << EOF
apiVersion: v1
kind: Service
metadata:  
  name: nginx-loadbalancer
  labels:
    app: nginx
spec:
  selector:
    run: nginx
  type: LoadBalancer
  ports:  
  - name: http
    port: 8083
    targetPort: 80
    protocol: TCP
EOF
```

Then apply the configuration

```bash
kubectl apply -f nginx-lb.yaml -n test
```

### Task 19. Check the LoadBalancer service

Run the following command to get the description of the configured service:

```bash
kubectl get svc -n test
```

You should have the similar update:

```console
eti-lab> kubectl get svc -n test
NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE
nginx-loadbalancer   LoadBalancer   10.96.139.196   172.18.255.200   8083:30604/TCP   25m
```

You can test access to the service using curl:

```bash
curl http://172.18.255.200:8083
```

You should have the similar update:

```console
eti-lab> curl http://172.18.255.200:8083
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

### Task 20. Delete the resource

Use the following commands to clean-up some resources:

```bash
kubectl delete ns test
kubectl delete pod nginx
kubectl delete svc nginx
```

You should have the similar output:

```console
eti-lab> kubectl delete ns test
namespace "test" deleted
eti-lab> kubectl delete pod nginx
pod "nginx" deleted
eti-lab> kubectl delete svc nginx
service "nginx" deleted
```


